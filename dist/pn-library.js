/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else if(typeof exports === 'object')
		exports["PN"] = factory();
	else
		root["PN"] = factory();
})(self, () => {
return /******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./src/dom/dom.js":
/*!************************!*\
  !*** ./src/dom/dom.js ***!
  \************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ProgressID: () => (/* binding */ ProgressID),\n/* harmony export */   audioElements: () => (/* binding */ audioElements),\n/* harmony export */   canvasElements: () => (/* binding */ canvasElements),\n/* harmony export */   createAudio: () => (/* binding */ createAudio),\n/* harmony export */   createCanvas: () => (/* binding */ createCanvas),\n/* harmony export */   createProgressBar: () => (/* binding */ createProgressBar),\n/* harmony export */   progressBarElements: () => (/* binding */ progressBarElements)\n/* harmony export */ });\n// dom.js\n\nvar canvasElements = [];\nvar audioElements = [];\nvar progressBarElements = [];\nvar ProgressID = 0;\n/**\n * Create a new canvas element and append it to the DOM.\n * Maintain a reference to the created canvas.\n * @param {Object} options - Options for the canvas (width, height, etc.)\n * @returns {HTMLCanvasElement} The created canvas element\n */\nfunction createCanvas() {\n  var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {\n    width: 800,\n    height: 600\n  };\n  var canvas = document.createElement(\"canvas\");\n  canvas.width = options.width;\n  canvas.height = options.height;\n  document.body.appendChild(canvas);\n  canvasElements.push(canvas);\n  return canvas;\n}\n\n/**\n * Create a new audio input element and append it to the DOM.\n * Maintain a reference to the created audio input.\n * @returns {HTMLAudioElement} The created audio element\n */\nfunction createAudio() {\n  var audio = document.createElement(\"audio\");\n  audio.controls = true;\n  document.body.appendChild(audio);\n  audioElements.push(audio);\n  return audio;\n}\nfunction createProgressBar() {\n  var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {\n    max: 100,\n    value: 0,\n    id: \"\"\n  };\n  var progressBarContainer = document.createElement(\"div\");\n  progressBarContainer.style.position = \"relative\";\n  progressBarContainer.style.width = \"100%\";\n  progressBarContainer.style.height = \"20px\";\n  progressBarContainer.style.backgroundColor = \"#e0e0e0\";\n  var progressBar = document.createElement(\"div\");\n  progressBar.style.position = \"absolute\";\n  progressBar.style.height = \"100%\";\n  progressBar.style.width = \"\".concat(options.value, \"%\");\n  progressBar.style.backgroundColor = \"#76c7c0\";\n  if (options.id) {\n    progressBar.id = options.id;\n    ProgressID = options.id;\n  }\n  progressBarContainer.appendChild(progressBar);\n  document.body.appendChild(progressBarContainer);\n  progressBarElements.push(progressBar);\n  return progressBar;\n}\n\n//# sourceURL=webpack://PN/./src/dom/dom.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EncoderProgress: () => (/* reexport safe */ _wave_encoder_js__WEBPACK_IMPORTED_MODULE_3__.EncoderProgress),\n/* harmony export */   InterweaveProgressCH1: () => (/* reexport safe */ _wave_encoder_js__WEBPACK_IMPORTED_MODULE_3__.InterweaveProgressCH1),\n/* harmony export */   InterweaveProgressCH2: () => (/* reexport safe */ _wave_encoder_js__WEBPACK_IMPORTED_MODULE_3__.InterweaveProgressCH2),\n/* harmony export */   PN: () => (/* reexport safe */ _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   ProcessorProgress: () => (/* reexport safe */ _input_wavProcessor_js__WEBPACK_IMPORTED_MODULE_7__.ProcessorProgress),\n/* harmony export */   audioElements: () => (/* reexport safe */ _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__.audioElements),\n/* harmony export */   canvasElements: () => (/* reexport safe */ _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__.canvasElements),\n/* harmony export */   createAudio: () => (/* reexport safe */ _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__.createAudio),\n/* harmony export */   createCanvas: () => (/* reexport safe */ _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__.createCanvas),\n/* harmony export */   createNote: () => (/* reexport safe */ _wave_player_js__WEBPACK_IMPORTED_MODULE_2__.createNote),\n/* harmony export */   createProgressBar: () => (/* reexport safe */ _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__.createProgressBar),\n/* harmony export */   createSong: () => (/* reexport safe */ _wave_player_js__WEBPACK_IMPORTED_MODULE_2__.createSong),\n/* harmony export */   instrument: () => (/* reexport safe */ _instruments_instrumentSelector_js__WEBPACK_IMPORTED_MODULE_1__.instrument),\n/* harmony export */   readWavFile: () => (/* reexport safe */ _input_wavProcessor_js__WEBPACK_IMPORTED_MODULE_7__.readWavFile),\n/* harmony export */   save: () => (/* reexport safe */ _output_wav_js__WEBPACK_IMPORTED_MODULE_4__.save),\n/* harmony export */   setDuration: () => (/* reexport safe */ _wave_setProperties_js__WEBPACK_IMPORTED_MODULE_5__.setDuration),\n/* harmony export */   setHarmonic: () => (/* reexport safe */ _wave_setProperties_js__WEBPACK_IMPORTED_MODULE_5__.setHarmonic),\n/* harmony export */   setVolume: () => (/* reexport safe */ _wave_setProperties_js__WEBPACK_IMPORTED_MODULE_5__.setVolume),\n/* harmony export */   singVoice: () => (/* reexport safe */ _wave_player_js__WEBPACK_IMPORTED_MODULE_2__.singVoice),\n/* harmony export */   yinReadWavFile: () => (/* reexport safe */ _input_yinWavProcessor_js__WEBPACK_IMPORTED_MODULE_8__.yinReadWavFile)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./pn.js */ \"./src/pn.js\");\n/* harmony import */ var _instruments_instrumentSelector_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./instruments/instrumentSelector.js */ \"./src/instruments/instrumentSelector.js\");\n/* harmony import */ var _wave_player_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./wave/player.js */ \"./src/wave/player.js\");\n/* harmony import */ var _wave_encoder_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./wave/encoder.js */ \"./src/wave/encoder.js\");\n/* harmony import */ var _output_wav_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./output/wav.js */ \"./src/output/wav.js\");\n/* harmony import */ var _wave_setProperties_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./wave/setProperties.js */ \"./src/wave/setProperties.js\");\n/* harmony import */ var _dom_dom_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./dom/dom.js */ \"./src/dom/dom.js\");\n/* harmony import */ var _input_wavProcessor_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./input/wavProcessor.js */ \"./src/input/wavProcessor.js\");\n/* harmony import */ var _input_yinWavProcessor_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./input/yinWavProcessor.js */ \"./src/input/yinWavProcessor.js\");\n// index.js - The entry point file for Webpack\n\n // Import the base PN object\n // Add PN.instrument method\n// Import other functions\n\n\n\n\n\n\n\n\n// Attach PN and other functions to the global window object to make them accessible\n\n\n\n//# sourceURL=webpack://PN/./src/index.js?");

/***/ }),

/***/ "./src/input/fft.js":
/*!**************************!*\
  !*** ./src/input/fft.js ***!
  \**************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   analyzeFrequencies: () => (/* binding */ analyzeFrequencies)\n/* harmony export */ });\nfunction _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\nfunction _iterableToArrayLimit(r, l) { var t = null == r ? null : \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t[\"return\"] && (u = t[\"return\"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }\nfunction _arrayWithHoles(r) { if (Array.isArray(r)) return r; }\n// Function to pad data to the next power of 2\nfunction padToPowerOfTwo(data) {\n  var nextPowerOfTwo = Math.pow(2, Math.ceil(Math.log2(data.length)));\n  var paddedData = new Array(nextPowerOfTwo).fill(0);\n  for (var i = 0; i < data.length; i++) {\n    paddedData[i] = data[i];\n  }\n  return paddedData;\n}\n\n// Function to perform FFT (recursive implementation)\nfunction fft(data) {\n  var n = data.length;\n  if (n <= 1) return data;\n\n  // Separate even and odd terms\n  var even = fft(data.filter(function (_, i) {\n    return i % 2 === 0;\n  }));\n  var odd = fft(data.filter(function (_, i) {\n    return i % 2 !== 0;\n  }));\n  var results = new Array(n).fill(0).map(function () {\n    return [0, 0];\n  });\n  for (var k = 0; k < n / 2; k++) {\n    var expTerm = -2 * Math.PI * k / n;\n    var cosine = Math.cos(expTerm);\n    var sine = Math.sin(expTerm);\n\n    // Calculate the real and imaginary parts\n    var real = cosine * odd[k][0] - sine * odd[k][1];\n    var imag = sine * odd[k][0] + cosine * odd[k][1];\n    results[k] = [even[k][0] + real, even[k][1] + imag];\n    results[k + n / 2] = [even[k][0] - real, even[k][1] - imag];\n  }\n  return results;\n}\n\n// Function to compute magnitudes from FFT output\nfunction computeMagnitudes(fftData) {\n  return fftData.map(function (_ref) {\n    var _ref2 = _slicedToArray(_ref, 2),\n      real = _ref2[0],\n      imag = _ref2[1];\n    return Math.sqrt(Math.pow(real, 2) + Math.pow(imag, 2));\n  });\n}\n\n// Function to calculate RMS for volume estimation\nfunction calculateRMS(data) {\n  var sumSquares = 0;\n  for (var i = 0; i < data.length; i++) {\n    sumSquares += data[i] * data[i];\n  }\n  return Math.sqrt(sumSquares / data.length);\n}\n\n// Function to analyze frequencies and volume in audio data\nfunction analyzeFrequencies(data, sampleRate) {\n  // Step 1: Pad data to the next power of 2\n  var paddedData = padToPowerOfTwo(data);\n\n  // Step 2: Convert padded data to complex format (real, imaginary) for FFT\n  var complexData = paddedData.map(function (value) {\n    return [value, 0];\n  });\n\n  // Step 3: Perform FFT on the complex data\n  var fftData = fft(complexData);\n\n  // Step 4: Calculate magnitudes\n  var magnitudes = computeMagnitudes(fftData);\n\n  // Step 5: Calculate frequencies\n  var frequencies = magnitudes.map(function (_, index) {\n    return index * sampleRate / paddedData.length;\n  });\n\n  // Step 6: Find the frequency with the highest magnitude (dominant frequency)\n  var maxIndex = 0;\n  for (var i = 1; i < magnitudes.length; i++) {\n    if (magnitudes[i] > magnitudes[maxIndex]) {\n      maxIndex = i;\n    }\n  }\n  var dominantFrequency = frequencies[maxIndex];\n\n  // Step 7: Calculate the volume using RMS\n  var volume = calculateRMS(data);\n\n  // Step 8: Calculate the chunk duration in seconds\n  var duration = data.length / sampleRate;\n  return {\n    dominantFrequency: dominantFrequency,\n    volume: volume,\n    duration: duration\n  };\n}\n\n//# sourceURL=webpack://PN/./src/input/fft.js?");

/***/ }),

/***/ "./src/input/parseStringInput.js":
/*!***************************************!*\
  !*** ./src/input/parseStringInput.js ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _iterableToArrayLimit(r, l) { var t = null == r ? null : \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t[\"return\"] && (u = t[\"return\"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }\nfunction _arrayWithHoles(r) { if (Array.isArray(r)) return r; }\nfunction _createForOfIteratorHelper(r, e) { var t = \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (!t) { if (Array.isArray(r) || (t = _unsupportedIterableToArray(r)) || e && r && \"number\" == typeof r.length) { t && (r = t); var _n = 0, F = function F() {}; return { s: F, n: function n() { return _n >= r.length ? { done: !0 } : { done: !1, value: r[_n++] }; }, e: function e(r) { throw r; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var o, a = !0, u = !1; return { s: function s() { t = t.call(r); }, n: function n() { var r = t.next(); return a = r.done, r; }, e: function e(r) { u = !0, o = r; }, f: function f() { try { a || null == t[\"return\"] || t[\"return\"](); } finally { if (u) throw o; } } }; }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\nfunction parseSongInput(songData) {\n  var parsedData = {};\n  var _iterator = _createForOfIteratorHelper(songData),\n    _step;\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var entry = _step.value;\n      var _entry$split = entry.split(\"[\"),\n        _entry$split2 = _slicedToArray(_entry$split, 2),\n        channel = _entry$split2[0],\n        songInfo = _entry$split2[1];\n\n      // Remove ']' from the songInfo to get the clean song data\n      var cleanSongInfo = songInfo.replace(\"]\", \"\");\n      var _cleanSongInfo$split = cleanSongInfo.split(\":\"),\n        _cleanSongInfo$split2 = _slicedToArray(_cleanSongInfo$split, 2),\n        durationStr = _cleanSongInfo$split2[0],\n        notesStr = _cleanSongInfo$split2[1];\n      var duration = parseFloat(durationStr); // Convert to float\n\n      // Split the notes by '-' for multiple notes\n      var notesArray = notesStr.split(\"-\");\n      if (!parsedData[channel]) {\n        parsedData[channel] = [];\n      }\n      parsedData[channel].push({\n        duration: duration,\n        notes: notesArray\n      });\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n  return parsedData;\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (parseSongInput);\n\n//# sourceURL=webpack://PN/./src/input/parseStringInput.js?");

/***/ }),

/***/ "./src/input/wavProcessor.js":
/*!***********************************!*\
  !*** ./src/input/wavProcessor.js ***!
  \***********************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ProcessorProgress: () => (/* binding */ ProcessorProgress),\n/* harmony export */   parseWav: () => (/* binding */ parseWav),\n/* harmony export */   processAudioData: () => (/* binding */ processAudioData),\n/* harmony export */   readWavFile: () => (/* binding */ readWavFile)\n/* harmony export */ });\n/* harmony import */ var _input_fft_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../input/fft.js */ \"./src/input/fft.js\");\n/* harmony import */ var _dom_dom_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../dom/dom.js */ \"./src/dom/dom.js\");\n// wavProcessor.js\n\n\nvar ProcessorProgress = 0;\n/**\n * Reads a WAV file from the provided URL, parses it, and processes the audio data.\n * @param {string} url - The URL of the WAV file to read.\n */\nfunction readWavFile(url, callback) {\n  fetch(url).then(function (response) {\n    return response.arrayBuffer();\n  }).then(function (buffer) {\n    var wavData = parseWav(buffer); // Parse the WAV file\n    var sampleRate = wavData.sampleRate;\n    var audioData = wavData.samples;\n\n    //console.log(\"WAV file parsed successfully\");\n    //console.log(\"Sample Rate: \", sampleRate);\n    //console.log(\"Number of samples: \", audioData.length);\n\n    var allVoiceFrequencies = processAudioData(audioData, sampleRate, 2);\n    //console.log(\"Voice F : \", voiceFrequencies);\n\n    if (callback) {\n      callback(allVoiceFrequencies); // Pass voiceFrequencies to the callback\n    }\n  })[\"catch\"](function (err) {\n    console.error(\"Error loading WAV file: \", err);\n  });\n}\n\n/**\n * Parses WAV file data from an ArrayBuffer.\n * @param {ArrayBuffer} buffer - The WAV file buffer.\n * @returns {Object} Parsed WAV data including sample rate and audio samples.\n */\nfunction parseWav(buffer) {\n  var view = new DataView(buffer);\n  var numChannels = view.getUint16(22, true);\n  var sampleRate = view.getUint32(24, true);\n  var bitsPerSample = view.getUint16(34, true);\n  var dataOffset = 44; // WAV header size (assumes no additional sub-chunks)\n  var bytesPerSample = bitsPerSample / 8;\n  var numSamples = Math.floor((view.byteLength - dataOffset) / (numChannels * bytesPerSample));\n\n  //console.log(\"Num Channels: \", numChannels);\n  //console.log(\"Sample Rate: \", sampleRate);\n  //console.log(\"Bits Per Sample: \", bitsPerSample);\n  //console.log(\"Number of Samples: \", numSamples);\n\n  var samples = new Float32Array(numSamples);\n  for (var i = 0; i < numSamples; i++) {\n    var sample = 0;\n    var sampleIndex = dataOffset + i * numChannels * bytesPerSample;\n\n    // Ensure we are not reading beyond the available buffer length\n    if (sampleIndex >= buffer.byteLength) {\n      console.error(\"Sample index exceeds buffer length at sample\", i);\n      break;\n    }\n\n    // If stereo, take only the left channel (instead of averaging)\n    if (numChannels === 2) {\n      var left = view.getInt16(sampleIndex, true);\n      sample = left;\n    } else {\n      sample = view.getInt16(sampleIndex, true);\n    }\n\n    // Normalize to [-1, 1] range\n    samples[i] = sample / 32768;\n  }\n  return {\n    sampleRate: sampleRate,\n    samples: samples\n  };\n}\n\n/**\n * @param {Float32Array} audioData - The audio data samples.\n * @param {number} sampleRate - The sample rate of the audio data.\n */\nfunction processAudioData(audioData, sampleRate, n) {\n  var chunkSize = 11025; // Adjusted chunk size for more effective analysis\n  var numChunks = Math.ceil(audioData.length / chunkSize);\n\n  // First loop: Process chunks from 0, 44100, 88200, ...\n  var results = [];\n  var ProcessorProgressCounter = 0;\n  for (var offsetMultiplier = 0; offsetMultiplier < n; offsetMultiplier++) {\n    var offset = 4410 * offsetMultiplier;\n    var voiceFrequencies = new Map();\n    for (var i = 0; i < Math.ceil(audioData.length / chunkSize); i++) {\n      var start = i * chunkSize + offset;\n      var end = Math.min(start + chunkSize, audioData.length);\n      var chunk = audioData.slice(start, end);\n      var result = (0,_input_fft_js__WEBPACK_IMPORTED_MODULE_0__.analyzeFrequencies)(chunk, sampleRate);\n      ProcessorProgressCounter++;\n      ProcessorProgress = ProcessorProgressCounter / (n * Math.ceil(audioData.length / chunkSize)) * 100;\n      console.log(\"Processor P \".concat(ProcessorProgress));\n      if (!isNaN(result.dominantFrequency)) {\n        //console.log(`Chunk (offset ${offset}): Frequency = ${result.dominantFrequency} Hz, Volume = ${result.volume}, Duration = ${result.duration}`);\n        voiceFrequencies.set(i, [result.dominantFrequency, result.volume, result.duration]);\n      } else {\n        //console.log(`Chunk (offset ${offset}): Frequency could not be determined (NaN)`);\n      }\n    }\n    results.push(voiceFrequencies);\n  }\n  return results;\n}\nfunction updateProgressBarById(id, value) {\n  var progressBar = document.getElementById(id);\n  progressBar.style.width = \"\".concat(value, \"%\");\n}\n\n// Export functions and data for CommonJS\n\n\n//# sourceURL=webpack://PN/./src/input/wavProcessor.js?");

/***/ }),

/***/ "./src/input/yin.js":
/*!**************************!*\
  !*** ./src/input/yin.js ***!
  \**************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   yin: () => (/* binding */ yin)\n/* harmony export */ });\nvar DEFAULT_THRESHOLD = 0.07;\nfunction difference(data) {\n  var n = data.length;\n  var results = new Float32Array(n);\n  var difference;\n  var summation;\n  var windowSize = Math.floor(n * 0.5);\n  for (var tau = 0; tau <= windowSize; tau++) {\n    summation = 0;\n    for (var j = 0; j < windowSize; j++) {\n      difference = data[j] - data[j + tau];\n      summation += difference * difference;\n    }\n    results[tau] = summation;\n  }\n  return results;\n}\nfunction cumulativeMeanNormalizedDifference(data) {\n  var n = data.length;\n  var results = new Float32Array(n);\n  var summation;\n  for (var tau = 0; tau < n; tau++) {\n    summation = 0;\n    for (var j = 0; j <= tau; j++) {\n      summation += data[j];\n    }\n    results[tau] = data[tau] / (summation / tau);\n  }\n  return results;\n}\nfunction absoluteThreshold(data, threshold) {\n  var k = Number.POSITIVE_INFINITY;\n  var tau;\n  for (var i = 0, n = data.length; i < n; i++) {\n    var x = data[i];\n    if (x < threshold) {\n      return i;\n    }\n    if (x < k) {\n      k = x;\n      tau = i;\n    }\n  }\n  return tau;\n}\nfunction bestLocalEstimate(data, tau) {\n  var i = tau + 1;\n  var n = data.length;\n  var k = data[tau];\n  while (i < n && data[i] < k) {\n    k = data[i];\n    i++;\n  }\n  return i - 1;\n}\n\n// Function to calculate RMS for volume estimation\nfunction calculateRMS(data) {\n  var sumSquares = 0;\n  for (var i = 0; i < data.length; i++) {\n    sumSquares += data[i] * data[i];\n  }\n  return Math.sqrt(sumSquares / data.length);\n}\n\n/**\n * Enhanced YIN algorithm to estimate fundamental frequency, duration, and volume of audio signal\n * @param {Float32Array} data The time-domain data for the audio signal\n * @param {Number} sampleRate The sample rate\n * @param {Number} [threshold = 0.07] The threshold\n * @returns {Object} An object with frequency, volume, and chunk duration\n */\nfunction yin(data, sampleRate) {\n  var aThreshold = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : DEFAULT_THRESHOLD;\n  // Step 1: Calculate the difference function\n  var diff = difference(data);\n\n  // Step 2: Calculate the cumulative mean normalized difference function\n  var cmnd = cumulativeMeanNormalizedDifference(diff);\n\n  // Step 3: Apply the threshold to find the first dip\n  var tau = absoluteThreshold(cmnd, aThreshold);\n  if (tau === -1) {\n    return {\n      frequency: NaN,\n      duration: 0,\n      volume: 0\n    }; // If no valid tau is found, return NaN\n  }\n\n  // Step 4: Refine the estimate using parabolic interpolation\n  var refinedTau = bestLocalEstimate(cmnd, tau);\n\n  // Step 5: Convert the refined lag into a frequency\n  var frequency = sampleRate / refinedTau;\n\n  // Step 6: Calculate the chunk's volume using RMS\n  var volume = calculateRMS(data);\n\n  // Step 7: Calculate the chunk duration in seconds\n  var duration = data.length / sampleRate;\n  return {\n    frequency: frequency,\n    volume: volume,\n    duration: duration\n  };\n}\n\n//# sourceURL=webpack://PN/./src/input/yin.js?");

/***/ }),

/***/ "./src/input/yinWavProcessor.js":
/*!**************************************!*\
  !*** ./src/input/yinWavProcessor.js ***!
  \**************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   yinParseWav: () => (/* binding */ yinParseWav),\n/* harmony export */   yinProcessAudioData: () => (/* binding */ yinProcessAudioData),\n/* harmony export */   yinReadWavFile: () => (/* binding */ yinReadWavFile)\n/* harmony export */ });\n/* harmony import */ var _input_yin_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../input/yin.js */ \"./src/input/yin.js\");\n\nvar voiceFrequencies = new Map();\nvar volumeDuration = [];\nfunction yinReadWavFile(url, callback) {\n  fetch(url).then(function (response) {\n    return response.arrayBuffer();\n  }).then(function (buffer) {\n    var wavData = yinParseWav(buffer); // Parse the WAV file\n    var sampleRate = wavData.sampleRate;\n    var audioData = wavData.samples;\n\n    //console.log(\"WAV file parsed successfully\");\n    //console.log(\"Sample Rate: \", sampleRate);\n    //console.log(\"Number of samples: \", audioData.length);\n\n    var voiceFrequencies = yinProcessAudioData(audioData, sampleRate);\n    //console.log(\"Voice F : \", voiceFrequencies);\n\n    if (callback) {\n      callback(voiceFrequencies); // Pass voiceFrequencies to the callback\n    }\n  })[\"catch\"](function (err) {\n    console.error(\"Error loading WAV file: \", err);\n  });\n}\nfunction yinParseWav(buffer) {\n  var view = new DataView(buffer);\n\n  // WAV file parsing: Extract header info and PCM data\n  var numChannels = view.getUint16(22, true);\n  var sampleRate = view.getUint32(24, true);\n  var bitsPerSample = view.getUint16(34, true);\n  var dataOffset = 44; // WAV header size (assumes no additional sub-chunks)\n  var bytesPerSample = bitsPerSample / 8;\n  var numSamples = Math.floor((view.byteLength - dataOffset) / (numChannels * bytesPerSample));\n  console.log(\"Num Channels: \", numChannels);\n  console.log(\"Sample Rate: \", sampleRate);\n  console.log(\"Bits Per Sample: \", bitsPerSample);\n  console.log(\"Number of Samples: \", numSamples);\n  var samples = new Float32Array(numSamples);\n  for (var i = 0; i < numSamples; i++) {\n    var sample = 0;\n    var sampleIndex = dataOffset + i * numChannels * bytesPerSample;\n\n    // Ensure we are not reading beyond the available buffer length\n    if (sampleIndex >= buffer.byteLength) {\n      console.error(\"Sample index exceeds buffer length at sample\", i);\n      break;\n    }\n\n    // If stereo, take only the left channel (instead of averaging)\n    if (numChannels === 2) {\n      var left = view.getInt16(sampleIndex, true);\n      sample = left;\n    } else {\n      sample = view.getInt16(sampleIndex, true);\n    }\n\n    // Normalize to [-1, 1] range\n    samples[i] = sample / 32768;\n  }\n  return {\n    sampleRate: sampleRate,\n    samples: samples\n  };\n}\nfunction yinProcessAudioData(audioData, sampleRate) {\n  var voiceFrequencies = new Map();\n  var chunkSize = 216; // Use 11025 samples for each chunk\n  var numChunks = Math.ceil(audioData.length / chunkSize);\n  var myObj1 = [];\n  console.log(\"numChunks : \" + numChunks);\n  var currentDuration;\n  for (var i = 0; i < numChunks; i++) {\n    var start = i * chunkSize;\n    var end = Math.min(start + chunkSize, audioData.length);\n    var chunk = audioData.slice(start, end);\n\n    // Call the analyzeFrequencies function\n    // Use the enhanced YIN algorithm to get frequency, duration, and volume\n    var result = (0,_input_yin_js__WEBPACK_IMPORTED_MODULE_0__.yin)(chunk, sampleRate);\n    if (!isNaN(result.frequency)) {\n      console.log(\"Chunk \".concat(i + 1, \": Frequency = \").concat(result.frequency, \" Hz, Volume = \").concat(result.volume, \", Duration = \").concat(result.duration));\n      voiceFrequencies.set(i, [result.frequency, result.volume, result.duration]);\n    } else {\n      console.log(\"Chunk \".concat(i + 1, \": Frequency could not be determined (NaN)\"));\n    }\n  }\n  console.log(\"Voice F : \", voiceFrequencies); // This will log after processing is complete\n  return voiceFrequencies;\n}\n\n// Export functions and data for CommonJS\n\n\n//# sourceURL=webpack://PN/./src/input/yinWavProcessor.js?");

/***/ }),

/***/ "./src/instruments/envelope.js":
/*!*************************************!*\
  !*** ./src/instruments/envelope.js ***!
  \*************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ADSRLinearEnvelope: () => (/* binding */ ADSRLinearEnvelope),\n/* harmony export */   ADSRLogEnvelope: () => (/* binding */ ADSRLogEnvelope),\n/* harmony export */   AcousticGuitar: () => (/* binding */ AcousticGuitar),\n/* harmony export */   Banjo: () => (/* binding */ Banjo),\n/* harmony export */   Cello: () => (/* binding */ Cello),\n/* harmony export */   EvolvingLead: () => (/* binding */ EvolvingLead),\n/* harmony export */   EvolvingLeadPad: () => (/* binding */ EvolvingLeadPad),\n/* harmony export */   FunckLead: () => (/* binding */ FunckLead),\n/* harmony export */   Organ60: () => (/* binding */ Organ60),\n/* harmony export */   PercussiveStaccatoPad: () => (/* binding */ PercussiveStaccatoPad),\n/* harmony export */   ThickBass: () => (/* binding */ ThickBass),\n/* harmony export */   Trumpet: () => (/* binding */ Trumpet),\n/* harmony export */   adsrExpEnvelope: () => (/* binding */ adsrExpEnvelope),\n/* harmony export */   ampAcousticGuitar: () => (/* binding */ ampAcousticGuitar),\n/* harmony export */   ampBanjo: () => (/* binding */ ampBanjo),\n/* harmony export */   ampCello: () => (/* binding */ ampCello),\n/* harmony export */   ampEffectedLeadPad: () => (/* binding */ ampEffectedLeadPad),\n/* harmony export */   ampEnvelope: () => (/* binding */ ampEnvelope),\n/* harmony export */   ampFunckLead: () => (/* binding */ ampFunckLead),\n/* harmony export */   ampOrgan60: () => (/* binding */ ampOrgan60),\n/* harmony export */   ampPercussiveStaccatoPad: () => (/* binding */ ampPercussiveStaccatoPad),\n/* harmony export */   ampThickBass: () => (/* binding */ ampThickBass),\n/* harmony export */   ampTrumpet: () => (/* binding */ ampTrumpet),\n/* harmony export */   envelopes: () => (/* binding */ envelopes),\n/* harmony export */   filterEnvelope: () => (/* binding */ filterEnvelope)\n/* harmony export */ });\n// envelope.js\n\n// Envelope functions control the shape of the note and how it's played\nvar envelopes = {};\nvar defaultParams = {\n  g: 1,\n  w: \"sine\",\n  t: 1,\n  f: 0,\n  v: 1,\n  a: 1,\n  h: 1,\n  d: 1,\n  s: 1,\n  r: 0,\n  p: 1,\n  q: 1,\n  k: 0\n};\n\n// ADSHR Envelope function\n\n// -- .\n//     \\\n//      \\\n// Drop envelope: cosine decay\n/*\nAttack (A): 0 (no attack phase)\nDecay (D): The entire duration is a decay phase, decaying from 1 to 0.\nSustain (S): 0 (no sustain)\nRelease (R): The function ends at 0, meaning the release is implicit.\n*/\n\nfunction ampEnvelope(time, attack, decay, sustain, release, noteDuration) {\n  attack = attack / 4;\n  decay = decay / 4;\n  sustain = sustain / 4;\n  release = release / 4;\n  if (time < attack) return time / attack; // Attack phase\n  if (time < attack + decay) return 1 - (1 - sustain) * (time - attack) / decay; // Decay phase\n  if (time < noteDuration) return sustain; // Sustain phase\n  if (time < noteDuration + release) return sustain * (1 - (time - noteDuration) / release); // Release phase\n  return 0; // After release\n}\nfunction filterEnvelope(attack, decay, sustain, release, time, duration) {\n  attack = attack / 4;\n  decay = decay / 4;\n  sustain = sustain / 4;\n  release = release / 4;\n  var minEnvelopeValue = 0.001; // Minimum envelope value to avoid cutoff = 0\n  if (time < attack) return Math.max(time / attack, minEnvelopeValue); // Attack phase\n  if (time < attack + decay) return Math.max(1 - (1 - sustain) * (time - attack) / decay, minEnvelopeValue); // Decay phase\n  return Math.max(sustain, minEnvelopeValue); // Sustain phase\n}\nfunction EvolvingLead(time, duration) {\n  var attack = 2.5;\n  var decay = 3.0;\n  var sustain = 0.35;\n  var release = 0;\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction EvolvingLeadPad(time, duration) {\n  var attack = 9; // Attack time in seconds\n  var decay = 2.5; // Decay time in seconds\n  var sustain = 0.35; // Sustain level (0 to 1)\n  var release = duration; // Ful\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction FunckLead(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 0.1; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 0;\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction ThickBass(time, duration) {\n  var attack = 0.5; // Attack time in seconds\n  var decay = 0.5; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 0.4; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction Organ60(time, duration) {\n  // Filter Envelope Parameters\n  var attack = 0; // Attack time in seconds\n  var decay = 0.16; // Decay time in seconds\n  var sustain = 0.34; // Sustain level (34%)\n  var release = 0; // Release time in seconds\n\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction PercussiveStaccatoPad(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 0.5; // Decay time in seconds\n  var sustain = 0.6; // Sustain level (60%)\n  var release = 0; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction Trumpet(time, duration) {\n  // Filter Envelope Parameters\n  var attack = 5.5; // Attack time in seconds\n  var decay = 1.7; // Decay time in seconds\n  var sustain = 0.18; // Sustain level (18%)\n  var release = 0.05; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction Banjo(time, duration) {\n  // Filter Envelope Parameters\n  var attack = 0; // Attack time in seconds\n  var decay = 0.19; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 0.19; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction Cello(time, duration) {\n  // Filter Envelope Parameters\n  var attack = 0; // Attack time in seconds\n  var decay = 3.29; // Decay time in seconds\n  var sustain = 0.78; // Sustain level (0%)\n  var release = duration; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\nfunction AcousticGuitar(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 3.35; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 0.29; // Release time in seconds\n  return filterEnvelope(attack, decay, sustain, release, time, duration);\n}\n\n/*-----------------------------------------------------------------------------*/\n\nfunction ampFunckLead(time, duration) {\n  // Amplifier Envelope Parameters\n  var attack = 0;\n  var decay = 0;\n  var sustain = 1; // Full sustain\n  var release = 0;\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampEffectedLeadPad(time, duration) {\n  var attack = 0;\n  var decay = 0;\n  var sustain = 1; // Full sustain\n  var release = duration; // Full release time\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampThickBass(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 0; // Decay time in seconds\n  var sustain = 1; // Full sustain\n  var release = 0.4; // Release time in seconds\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampPercussiveStaccatoPad(time, duration) {\n  var attack = 0;\n  var decay = 0;\n  var sustain = 1;\n  var release = 5;\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampOrgan60(time, duration) {\n  // Amplifier Envelope Parameters\n  var attack = 0; // Attack time in seconds\n  var decay = 0; // Decay time in seconds\n  var sustain = 1; // Full sustain\n  var release = 0.17; // Release time in seconds\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampTrumpet(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 0; // Decay time in seconds\n  var sustain = 1; // Full sustain\n  var release = 1;\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampBanjo(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 0.67; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 0.67; // Release time in seconds\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampCello(time, duration) {\n  var attack = 0.06; // Attack time in seconds\n  var decay = duration; // Decay time in seconds\n  var sustain = 1; // Sustain level (0%)\n  var release = 0.3; // Release time in seconds\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction ampAcousticGuitar(time, duration) {\n  var attack = 0; // Attack time in seconds\n  var decay = 1.7; // Decay time in seconds\n  var sustain = 0; // Sustain level (0%)\n  var release = 1.7; // Release time in seconds\n  return ampEnvelope(time, attack, decay, sustain, release, duration);\n}\nfunction adsrExpEnvelope(t, duration, params) {\n  var a = params.a,\n    d = params.d,\n    h = params.h,\n    s = params.s,\n    r = params.r;\n  a *= duration;\n  d *= duration;\n  h *= duration;\n  r *= duration;\n  var expScale = function expScale(x, min, max) {\n    return (Math.exp((x - min) / (max - min)) - 1) / (Math.exp(1) - 1);\n  };\n  var amplitude = 0;\n  if (t <= a) {\n    // Exponential attack\n    amplitude = expScale(t, 0, a);\n  } else if (t <= a + d) {\n    // Exponential decay\n    amplitude = 1 - expScale(t - a, 0, d) * (1 - s);\n  } else if (t <= a + d + h) {\n    amplitude = s; // Sustain remains constant\n  } else if (t <= a + d + h + r) {\n    // Exponential release\n    amplitude = s * (1 - expScale(t - (a + d + h), 0, r));\n  } else {\n    amplitude = 0;\n  }\n  return amplitude;\n}\nfunction ADSRLogEnvelope(t, duration, params) {\n  var a = params.a,\n    d = params.d,\n    h = params.h,\n    s = params.s,\n    r = params.r;\n  a *= duration;\n  d *= duration;\n  h *= duration;\n  r *= duration;\n  var logScale = function logScale(x, min, max) {\n    return Math.log10(1 + 9 * (x - min) / (max - min));\n  };\n  var amplitude = 0;\n  if (t <= a) {\n    // Logarithmic attack\n    amplitude = logScale(t, 0, a);\n  } else if (t <= a + d) {\n    // Logarithmic decay\n    amplitude = 1 - logScale(t - a, 0, d) * (1 - s);\n  } else if (t <= a + d + h) {\n    amplitude = s; // Sustain remains constant\n  } else if (t <= a + d + h + r) {\n    // Logarithmic release\n    amplitude = s * (1 - logScale(t - (a + d + h), 0, r));\n  } else {\n    amplitude = 0;\n  }\n  return amplitude;\n}\nfunction ADSRLinearEnvelope(t, duration, params) {\n  var a = params.a,\n    d = params.d,\n    h = params.h,\n    s = params.s,\n    r = params.r,\n    k = params.k,\n    v = params.v,\n    g = params.g,\n    f = params.f;\n  a = a / 4;\n  d = d / 4;\n  s = s / 4;\n  r = r / 4;\n  a *= duration;\n  d *= duration;\n  h *= duration;\n  r *= duration;\n  var amplitude = 0;\n  if (t <= a) {\n    amplitude = t / a;\n  } else if (t <= a + d) {\n    amplitude = 1 - (t - a) / d * (1 - s);\n  } else if (t <= a + d + h) {\n    amplitude = s;\n  } else if (t <= a + d + h + r) {\n    amplitude = s * (1 - (t - (a + d + h)) / r);\n  } else {\n    amplitude = 0;\n  }\n  return amplitude * v;\n}\nenvelopes[\"ampEnvelope\"] = ampEnvelope;\nenvelopes[\"ampThickBass\"] = ampThickBass;\nenvelopes[\"ThickBass\"] = ThickBass;\nenvelopes[\"ampPercussiveStaccatoPad\"] = ampPercussiveStaccatoPad;\nenvelopes[\"PercussiveStaccatoPad\"] = PercussiveStaccatoPad;\nenvelopes[\"ampOrgan60\"] = ampOrgan60;\nenvelopes[\"Organ60\"] = Organ60;\nenvelopes[\"Trumpet\"] = Trumpet;\nenvelopes[\"ampTrumpet\"] = ampTrumpet;\nenvelopes[\"Banjo\"] = Banjo;\nenvelopes[\"ampBanjo\"] = ampBanjo;\nenvelopes[\"ampCello\"] = ampCello;\nenvelopes[\"Cello\"] = Cello;\nenvelopes[\"AcousticGuitar\"] = AcousticGuitar;\nenvelopes[\"ampAcousticGuitar\"] = ampAcousticGuitar;\n\n\n//# sourceURL=webpack://PN/./src/instruments/envelope.js?");

/***/ }),

/***/ "./src/instruments/instrumentSelector.js":
/*!***********************************************!*\
  !*** ./src/instruments/instrumentSelector.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   instrument: () => (/* binding */ instrument)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n/* harmony import */ var _instruments_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./instruments.js */ \"./src/instruments/instruments.js\");\n// instrumentSelector.js\n\n\n // Assuming you have an Instruments class defined\n\n// Helper to select an instrument\nfunction instrument(instrumentName) {\n  switch (instrumentName.toLowerCase()) {\n    case \"trumpet\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().Trumpet();\n      break;\n    case \"thickbass\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().ThickBass();\n      break;\n    case \"funcklead\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().FunckLead();\n      break;\n    case \"organ60\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().Organ60();\n      break;\n    case \"banjo\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().Banjo();\n      break;\n    case \"cello\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().Cello();\n      break;\n    case \"acousticguitar\":\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_js__WEBPACK_IMPORTED_MODULE_1__.Instruments().AcousticGuitar();\n      break;\n    default:\n      console.log(\"Instrument not found!\");\n      return;\n  }\n  console.log(\"Selected instrument: \".concat(instrumentName));\n}\n\n\n//# sourceURL=webpack://PN/./src/instruments/instrumentSelector.js?");

/***/ }),

/***/ "./src/instruments/instruments.js":
/*!****************************************!*\
  !*** ./src/instruments/instruments.js ***!
  \****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Instruments: () => (/* binding */ Instruments)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n/* harmony import */ var _envelope_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./envelope.js */ \"./src/instruments/envelope.js\");\n/* harmony import */ var _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../wave/harmonic.js */ \"./src/wave/harmonic.js\");\n/* harmony import */ var _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../wave/filter.js */ \"./src/wave/filter.js\");\n/* harmony import */ var _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../wave/lowFrequency.js */ \"./src/wave/lowFrequency.js\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError(\"Cannot call a class as a function\"); }\nfunction _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }\nfunction _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", { writable: !1 }), e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\n//instruments.js\n\n // Assuming drop is an envelope function\n\n\n\nvar Instruments = /*#__PURE__*/function () {\n  function Instruments() {\n    _classCallCheck(this, Instruments);\n  }\n  return _createClass(Instruments, [{\n    key: \"ThickBass\",\n    value: function ThickBass() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 110;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.square;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = -12;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpThickBass;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ThickBass;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfThickBass;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.08;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"ThickBass\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampThickBass;\n    }\n  }, {\n    key: \"FunckLead\",\n    value: function FunckLead() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 5;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpFunckLead;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.FunckLead;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfFunckLead;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"FunckLead\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampFunckLead;\n    }\n  }, {\n    key: \"PercussiveStaccatoPad\",\n    value: function PercussiveStaccatoPad() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.square;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = -12;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpPercussiveStaccatoPad;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.PercussiveStaccatoPad;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfPercussiveStaccatoPad;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0.02;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = true;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"PercussiveStaccatoPad\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampPercussiveStaccatoPad;\n    }\n  }, {\n    key: \"Organ60\",\n    value: function Organ60() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.triangle;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.triangle;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = -12;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpOrgan60;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.Organ60;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfOrgan60;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0.02;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = true;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"Organ60\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampOrgan60;\n    }\n  }, {\n    key: \"Trumpet\",\n    value: function Trumpet() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 7;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpTrumpet;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.Trumpet;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfTrumpet;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = false;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"Trumpet\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampTrumpet;\n    }\n  }, {\n    key: \"Banjo\",\n    value: function Banjo() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 5;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2 = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1 = 0.2;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2 = 0.1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.Banjo;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfBanjo;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = false;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio = [1, 0.8, 1];\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"Banjo\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampBanjo;\n    }\n  }, {\n    key: \"Cello\",\n    value: function Cello() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sawtooth;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.square;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 5;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2 = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1 = 0.2;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2 = 0.1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.Cello;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfCello;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = false;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio = [1, 1, 1];\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"Cello\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampCello;\n    }\n  }, {\n    key: \"AcousticGuitar2\",\n    value: function AcousticGuitar2() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 10;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpCello;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2 = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpCello;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1 = 0.25;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2 = 0.1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.Cello;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = false;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio = [1, 0.9, 1];\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"AcousticGuitar\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampAcousticGuitar;\n    }\n  }, {\n    key: \"AcousticGuitar\",\n    value: function AcousticGuitar() {\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].frequency = 440;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2 = _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.pulseWave;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step = 10;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2 = _wave_filter_js__WEBPACK_IMPORTED_MODULE_3__.LpDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1 = 0.25;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2 = 0.1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv = _envelope_js__WEBPACK_IMPORTED_MODULE_1__.AcousticGuitar;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave = _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_4__.LfDefault;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime = 0.00001;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier = 1;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel = 0;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState = false;\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio = [1, 0.9, 1];\n      _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName = \"AcousticGuitar\";\n      return _envelope_js__WEBPACK_IMPORTED_MODULE_1__.ampAcousticGuitar;\n    }\n  }]);\n}();\n\n//# sourceURL=webpack://PN/./src/instruments/instruments.js?");

/***/ }),

/***/ "./src/output/channels.js":
/*!********************************!*\
  !*** ./src/output/channels.js ***!
  \********************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   foureo: () => (/* binding */ foureo),\n/* harmony export */   mono: () => (/* binding */ mono),\n/* harmony export */   stereo: () => (/* binding */ stereo)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n/* harmony import */ var _wave_encoder_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../wave/encoder.js */ \"./src/wave/encoder.js\");\n\n\n\n// Create the stereo output by interleaving two channels (left and right)\n\n// Create the stereo output by interleaving two channels (left and right)\nfunction mono() {\n  var c1 = _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].songDataOutput;\n  return c1;\n}\nfunction foureo() {\n  var c1 = _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].songDataOutput;\n  return c1;\n}\nfunction stereo() {\n  var leftChannel = _wave_encoder_js__WEBPACK_IMPORTED_MODULE_1__.LeftChannel;\n  var rightChannel = _wave_encoder_js__WEBPACK_IMPORTED_MODULE_1__.RightChannel;\n  return {\n    leftChannel: leftChannel,\n    rightChannel: rightChannel\n  };\n}\n\n\n//# sourceURL=webpack://PN/./src/output/channels.js?");

/***/ }),

/***/ "./src/output/wav.js":
/*!***************************!*\
  !*** ./src/output/wav.js ***!
  \***************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   save: () => (/* binding */ save)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n/* harmony import */ var _channels_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./channels.js */ \"./src/output/channels.js\");\n\n\n\n// Function to create WAV header using Uint8Array\nfunction writeWaveHeader(dataLength, sampleRate) {\n  var numChannels = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 2;\n  var bitsPerSample = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 16;\n  var byteRate = sampleRate * numChannels * bitsPerSample / 8;\n  var blockAlign = numChannels * bitsPerSample / 8;\n\n  // Uint8Array with a size of 44 bytes for the header\n  var buffer = new Uint8Array(44);\n  var view = new DataView(buffer.buffer);\n\n  // \"RIFF\" chunk descriptor\n  buffer.set([82, 73, 70, 70], 0); // \"RIFF\"\n  view.setUint32(4, 36 + dataLength, false); // Chunk size\n  buffer.set([87, 65, 86, 69], 8); // \"WAVE\"\n\n  // \"fmt \" sub-chunk\n  buffer.set([102, 109, 116, 32], 12); // \"fmt \"\n  view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)\n  view.setUint16(20, 1, true); // AudioFormat (1 for PCM)\n  view.setUint16(22, numChannels, true); // NumChannels\n  view.setUint32(24, sampleRate, true); // SampleRate\n  view.setUint32(28, byteRate, true); // ByteRate\n  view.setUint16(32, blockAlign, true); // BlockAlign\n  view.setUint16(34, bitsPerSample, true); // BitsPerSample\n\n  // \"data\" sub-chunk\n  buffer.set([100, 97, 116, 97], 36); // \"data\"\n  view.setUint32(40, dataLength, false); // Subchunk2Size (data length)\n\n  return buffer;\n}\n\n// Function to save WAV file\nfunction save() {\n  var fileName = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"play-noise-\".concat(_pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrumentName);\n  var sampleRate = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 44100;\n  var volume = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 5000;\n  var _stereo = (0,_channels_js__WEBPACK_IMPORTED_MODULE_1__.stereo)(),\n    leftChannel = _stereo.leftChannel,\n    rightChannel = _stereo.rightChannel; // Get stereo audio data\n  var bitsPerSample = 16;\n  var numChannels = 2; // Stereo\n\n  var maxVolume = 32767;\n  var volumeScale = maxVolume / volume;\n\n  // Ensure both channels have the same length\n  var dataLength = leftChannel.length;\n\n  // Create buffer for audio data (2 bytes per sample per channel)\n  var buffer = new Uint8Array(dataLength * numChannels * 2);\n  var view = new DataView(buffer.buffer);\n  for (var i = 0; i < dataLength; i++) {\n    var leftSample = Math.max(-1, Math.min(1, leftChannel[i] * volumeScale));\n    var rightSample = Math.max(-1, Math.min(1, rightChannel[i] * volumeScale));\n    var leftIntSample = Math.floor(leftSample * 32767);\n    var rightIntSample = Math.floor(rightSample * 32767);\n\n    // Write samples for left and right channels\n    view.setInt16(i * 4, leftIntSample, true); // Left channel\n    view.setInt16(i * 4 + 2, rightIntSample, true); // Right channel\n  }\n\n  // Create WAV header\n  var waveHeader = writeWaveHeader(buffer.length, sampleRate, numChannels, bitsPerSample);\n\n  // Combine header and audio data into one buffer\n  var wavFile = new Uint8Array(waveHeader.length + buffer.length);\n  wavFile.set(waveHeader, 0);\n  wavFile.set(buffer, waveHeader.length);\n\n  // Create a Blob from the WAV data\n  var blob = new Blob([wavFile], {\n    type: \"audio/wav\"\n  });\n\n  // Create a download link and trigger it\n  var a = document.createElement(\"a\");\n  a.href = URL.createObjectURL(blob);\n  a.download = \"\".concat(fileName, \".wav\");\n  document.body.appendChild(a);\n  a.click();\n  document.body.removeChild(a);\n  console.log(\"WAV file saved as \".concat(fileName));\n}\n\n//# sourceURL=webpack://PN/./src/output/wav.js?");

/***/ }),

/***/ "./src/pn.js":
/*!*******************!*\
  !*** ./src/pn.js ***!
  \*******************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _pitchFrequencies_json__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./pitchFrequencies.json */ \"./src/pitchFrequencies.json\");\n/* harmony import */ var _instruments_envelope_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./instruments/envelope.js */ \"./src/instruments/envelope.js\");\n/* harmony import */ var _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./wave/harmonic.js */ \"./src/wave/harmonic.js\");\n/* harmony import */ var _wave_lowFrequency_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./wave/lowFrequency.js */ \"./src/wave/lowFrequency.js\");\n/* harmony import */ var _wave_filter_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./wave/filter.js */ \"./src/wave/filter.js\");\n// pn.js\n\n\n\n\n\nvar PN = {\n  currentInstrument: null,\n  pitchFrequencies: _pitchFrequencies_json__WEBPACK_IMPORTED_MODULE_0__,\n  duration: 0.5,\n  // Default duration in seconds\n  volume: 0.2,\n  // Default volume level\n  harmonic1: _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sine,\n  // Default harmonic function\n  harmonic2: _wave_harmonic_js__WEBPACK_IMPORTED_MODULE_2__.sine,\n  songDataOutput: null,\n  key: \"C5#\",\n  step: 1,\n  filter: null,\n  filter2: _wave_filter_js__WEBPACK_IMPORTED_MODULE_4__.LpDefault,\n  width1: 0,\n  width2: 0,\n  filterEnv: null,\n  lfoWave: null,\n  glideTime: null,\n  semiTone: null,\n  multipliyer: 1,\n  noiseLevel: 0,\n  noiseState: false,\n  ratio: [1, 1, 2],\n  currentInstrumentName: null\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PN);\n\n//# sourceURL=webpack://PN/./src/pn.js?");

/***/ }),

/***/ "./src/wave/encoder.js":
/*!*****************************!*\
  !*** ./src/wave/encoder.js ***!
  \*****************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   EncoderProgress: () => (/* binding */ EncoderProgress),\n/* harmony export */   InterweaveProgressCH1: () => (/* binding */ InterweaveProgressCH1),\n/* harmony export */   InterweaveProgressCH2: () => (/* binding */ InterweaveProgressCH2),\n/* harmony export */   LeftChannel: () => (/* binding */ LeftChannel),\n/* harmony export */   Note: () => (/* binding */ Note),\n/* harmony export */   RightChannel: () => (/* binding */ RightChannel),\n/* harmony export */   Tune: () => (/* binding */ Tune)\n/* harmony export */ });\n/* harmony import */ var _synth_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./synth.js */ \"./src/wave/synth.js\");\nfunction _createForOfIteratorHelper(r, e) { var t = \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (!t) { if (Array.isArray(r) || (t = _unsupportedIterableToArray(r)) || e && r && \"number\" == typeof r.length) { t && (r = t); var _n = 0, F = function F() {}; return { s: F, n: function n() { return _n >= r.length ? { done: !0 } : { done: !1, value: r[_n++] }; }, e: function e(r) { throw r; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var o, a = !0, u = !1; return { s: function s() { t = t.call(r); }, n: function n() { var r = t.next(); return a = r.done, r; }, e: function e(r) { u = !0, o = r; }, f: function f() { try { a || null == t[\"return\"] || t[\"return\"](); } finally { if (u) throw o; } } }; }\nfunction _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _iterableToArrayLimit(r, l) { var t = null == r ? null : \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t[\"return\"] && (u = t[\"return\"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }\nfunction _arrayWithHoles(r) { if (Array.isArray(r)) return r; }\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _toConsumableArray(r) { return _arrayWithoutHoles(r) || _iterableToArray(r) || _unsupportedIterableToArray(r) || _nonIterableSpread(); }\nfunction _nonIterableSpread() { throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _iterableToArray(r) { if (\"undefined\" != typeof Symbol && null != r[Symbol.iterator] || null != r[\"@@iterator\"]) return Array.from(r); }\nfunction _arrayWithoutHoles(r) { if (Array.isArray(r)) return _arrayLikeToArray(r); }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\nfunction _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError(\"Cannot call a class as a function\"); }\nfunction _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }\nfunction _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", { writable: !1 }), e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\n\n\nvar LeftChannel;\nvar RightChannel;\n// Define pitch and keys globally\nvar pitch = {};\nvar tuneKey = {};\nvar sharpKeys = [];\nvar flatKeys = [];\nvar EncoderProgress = 0;\nvar InterweaveProgressCH1 = 0;\nvar InterweaveProgressCH2 = 0;\n\n// Initialize pitches and keys\nsetupPitches();\nsetupKeys();\n\n// Note class representing a musical note\nvar Note = /*#__PURE__*/function () {\n  function Note() {\n    var pitch = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n    var accidental = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];\n    var length = arguments.length > 2 ? arguments[2] : undefined;\n    var env = arguments.length > 3 ? arguments[3] : undefined;\n    var har1 = arguments.length > 4 ? arguments[4] : undefined;\n    var har2 = arguments.length > 5 ? arguments[5] : undefined;\n    var step = arguments.length > 6 ? arguments[6] : undefined;\n    var fil = arguments.length > 7 ? arguments[7] : undefined;\n    var fil2 = arguments.length > 8 ? arguments[8] : undefined;\n    var width1 = arguments.length > 9 ? arguments[9] : undefined;\n    var width2 = arguments.length > 10 ? arguments[10] : undefined;\n    var filEnv = arguments.length > 11 ? arguments[11] : undefined;\n    var lfoWave = arguments.length > 12 ? arguments[12] : undefined;\n    var glideTime = arguments.length > 13 ? arguments[13] : undefined;\n    var vol = arguments.length > 14 ? arguments[14] : undefined;\n    var multi = arguments.length > 15 ? arguments[15] : undefined;\n    var noiseL = arguments.length > 16 ? arguments[16] : undefined;\n    var noiseS = arguments.length > 17 ? arguments[17] : undefined;\n    var ratio = arguments.length > 18 ? arguments[18] : undefined;\n    _classCallCheck(this, Note);\n    this.pitch = Array.isArray(pitch) ? pitch : [];\n    this.accidental = accidental.length ? accidental : Array(this.pitch.length).fill(0);\n    this.length = length;\n    this.env = env;\n    this.har1 = har1;\n    this.har2 = har2;\n    this.step = step;\n    this.fil = fil;\n    this.fil2 = fil2;\n    this.width1 = width1;\n    this.width2 = width2;\n    this.filEnv = filEnv;\n    this.lfoWave = lfoWave;\n    this.glideTime = glideTime;\n    this.vol = vol;\n    this.multi = multi;\n    this.noiseL = noiseL;\n    this.noiseS = noiseS;\n    this.ratio = ratio;\n  }\n  return _createClass(Note, [{\n    key: \"encodeNote\",\n    value: function encodeNote() {\n      var _this = this;\n      if (this.pitch.length === 0) {\n        return (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.rest)(this.length); // Handle rest\n      }\n      var noteDataArray = this.pitch.map(function (p, i) {\n        var adjustedPitch = p + (_this.accidental[i] || 0);\n        var frequencyValue = adjustedPitch;\n        return (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.noteData)(frequencyValue, _this.length, _this.env, _this.har1, _this.har2, _this.step, _this.fil, _this.fil2, _this.width1, _this.width2, _this.filEnv, _this.lfoWave, _this.glideTime, _this.vol, _this.multi, _this.noiseL, _this.noiseS, _this.ratio);\n      });\n      return concatNotes.apply(void 0, _toConsumableArray(noteDataArray));\n    }\n  }]);\n}();\nvar Tune = /*#__PURE__*/function () {\n  function Tune(key) {\n    var _this2 = this;\n    _classCallCheck(this, Tune);\n    this.key = key;\n    // Assign channels dynamically while maintaining numbered references\n    for (var _len = arguments.length, channels = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      channels[_key - 1] = arguments[_key];\n    }\n    this.channels = channels.map(function (ch) {\n      return _this2.ensureNotes(ch || []);\n    });\n\n    // Optionally assign numbered properties for backward compatibility\n    this.channels.forEach(function (channel, index) {\n      _this2[\"ch\".concat(index + 1)] = channel;\n    });\n  }\n\n  // Ensure that all items in the array are instances of the Note class\n  return _createClass(Tune, [{\n    key: \"ensureNotes\",\n    value: function ensureNotes(notes) {\n      return notes.map(function (note) {\n        if (note instanceof Note) {\n          return note;\n        } else {\n          return new Note(note.pitch, note.accidental, note.length, note.env, note.har, note.vol);\n        }\n      });\n    }\n  }, {\n    key: \"encode\",\n    value: function encode() {\n      var _this3 = this;\n      var acc = (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.inKey)(sharpKeys, this.key) ? 1 : (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.inKey)(flatKeys, this.key) ? -1 : 0;\n      this.channels.forEach(function (channel) {\n        channel.forEach(function (note) {\n          return adjustAccidentals(note, acc);\n        });\n      });\n      var channelData = []; // Array to hold data for all channels\n      var currentInputInstrument = (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.getInputInstrument)();\n      var numberOfChannels = 100;\n      var channels = Array.from({\n        length: numberOfChannels\n      }, function (_, i) {\n        return _this3[\"ch\".concat(i + 1)];\n      });\n      var EncoderProgressCounter = 0;\n      for (var i = 0; i < channels.length; i++) {\n        var channel = channels[i];\n        var channelEncodedData = [];\n        for (var j = 0; j < channel.length; j++) {\n          var note = channel[j];\n          //console.log(`Note ch${i + 1} ${JSON.stringify(note)}`);\n\n          var encoded = note.encodeNote();\n          channelEncodedData.push(encoded);\n          EncoderProgressCounter++;\n          EncoderProgress = EncoderProgressCounter / (channel.length * channel.length) * 100;\n          console.log(\"Encoding ch\".concat(EncoderProgress, \" %\"));\n        }\n        channelData.push(channelEncodedData);\n      }\n\n      // Flattening all channel data\n      var flattenedChannels = channelData.map(function (data) {\n        return data.flat();\n      });\n\n      // Dynamically assign flattened data to c1, c2, c3, ...\n      var _flattenedChannels = _slicedToArray(flattenedChannels, 4),\n        c1 = _flattenedChannels[0],\n        c2 = _flattenedChannels[1],\n        c3 = _flattenedChannels[2],\n        c4 = _flattenedChannels[3]; // Adjust based on the number of channels you expect\n      // Calculate maxLength dynamically based on all channels\n      var maxLength = Math.max.apply(Math, _toConsumableArray(flattenedChannels.map(function (channel) {\n        return channel.length;\n      })));\n      var overlaidData = new Array(maxLength).fill(0);\n      var InterweaveProgressCounterCH1 = 0;\n\n      // Define offsets dynamically\n      var offsets = flattenedChannels.map(function (_, i) {\n        return i * 2205;\n      });\n\n      // Overlay data for all channels1\n      for (var chanIndex = 0; chanIndex < flattenedChannels.length; chanIndex++) {\n        var offset = offsets[chanIndex];\n        var _channelData = flattenedChannels[chanIndex];\n        for (var _i = 0; _i < _channelData.length; _i++) {\n          overlaidData[_i + offset] += _channelData[_i];\n        }\n      }\n\n      //return overlaidData;\n      LeftChannel = overlaidData;\n      RightChannel = overlaidData;\n    }\n  }, {\n    key: \"encodePlane\",\n    value: function encodePlane() {\n      var acc = (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.inKey)(sharpKeys, this.key) ? 1 : (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.inKey)(flatKeys, this.key) ? -1 : 0;\n      this.ch1.forEach(function (note) {\n        return adjustAccidentals(note, acc);\n      });\n      this.ch2.forEach(function (note) {\n        return adjustAccidentals(note, acc);\n      });\n      var ch1Data = [];\n      var ch2Data = [];\n      var currentInputInstrument = (0,_synth_js__WEBPACK_IMPORTED_MODULE_0__.getInputInstrument)();\n      for (var i = 0; i < this.ch1.length; i++) {\n        var note = this.ch1[i];\n        console.log(\"Note ch1 \".concat(JSON.stringify(note)));\n        var encoded = note.encodeNote();\n        ch1Data.push(encoded);\n        console.log(encoded);\n      }\n      for (var _i2 = 0; _i2 < this.ch2.length; _i2++) {\n        var _note = this.ch2[_i2];\n        console.log(\"Note ch2 \".concat(JSON.stringify(_note)));\n        var _encoded = _note.encodeNote();\n        ch2Data.push(_encoded);\n      }\n\n      //    return stereo(ch1Data.flat(), ch2Data.flat());\n\n      LeftChannel = ch1Data.flat();\n      RightChannel = ch2Data.flat();\n      console.log(LeftChannel);\n      console.log(RightChannel);\n    }\n  }]);\n}();\nfunction concatNotes() {\n  for (var _len2 = arguments.length, notes = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n    notes[_key2] = arguments[_key2];\n  }\n  // Check if there are any notes\n  if (notes.length === 0) return [];\n\n  // Get the length of the first note (to compare lengths of all notes)\n  var length = notes[0].length;\n\n  // Ensure all notes have the same length\n  for (var _i3 = 0, _notes = notes; _i3 < _notes.length; _i3++) {\n    var note = _notes[_i3];\n    if (note.length !== length) {\n      throw new Error(\"Length of notes are not the same\");\n    }\n  }\n\n  // Create an array to hold the concatenated result\n  var data = new Array(length).fill(0);\n\n  // Add up all the notes at each index\n  for (var i = 0; i < length; i++) {\n    var _iterator = _createForOfIteratorHelper(notes),\n      _step;\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var _note2 = _step.value;\n        data[i] += _note2[i];\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n  }\n  return data;\n}\n\n// Adjust accidentals for each note based on key signature\nfunction adjustAccidentals(note, acc) {\n  if (!note.pitch || !Array.isArray(note.pitch) || note.pitch.length === 0) {\n    note.pitch = [];\n  }\n  if (!note.accidental || !Array.isArray(note.accidental)) {\n    note.accidental = Array(note.pitch.length).fill(0);\n  }\n  note.accidental = note.accidental.map(function (a) {\n    return a + acc;\n  });\n}\nfunction setupPitches() {\n  var notes = [\"c\", \"d\", \"e\", \"f\", \"g\", \"a\", \"b\"];\n  var nums = [-57, -55, -53, -52, -50, -48, -46];\n  var _loop = function _loop(i) {\n    notes.forEach(function (note, j) {\n      nums[j] += 12;\n      pitch[\"\".concat(note).concat(i)] = nums[j];\n    });\n  };\n  for (var i = 1; i < 8; i++) {\n    _loop(i);\n  }\n}\n\n// Initialize the tuneKey array, which is used to apply the key signature to notes\n\nfunction setupKeys() {\n  tuneKey[\"C\"] = [];\n  var sharpKeys = [\"G\", \"D\", \"A\", \"E\", \"B\", \"F#\", \"C#\"];\n  var sharpNotes = [pitch[\"f1\"], pitch[\"c1\"], pitch[\"g1\"], pitch[\"d1\"], pitch[\"a1\"], pitch[\"e1\"], pitch[\"b1\"]];\n  sharpKeys.forEach(function (key, i) {\n    var k = [];\n    for (var j = 0; j < i + 1; j++) {\n      for (var l = 1; l < 6; l++) {\n        k.push(sharpNotes[j] + 12 * l);\n      }\n    }\n    tuneKey[key] = k;\n  });\n  var flatKeys = [\"F\", \"Bb\", \"Eb\", \"Ab\", \"Db\", \"Gb\", \"Cb\"];\n  var flatNotes = [pitch[\"b1\"], pitch[\"e1\"], pitch[\"a1\"], pitch[\"d1\"], pitch[\"g1\"], pitch[\"c1\"], pitch[\"f1\"]];\n  flatKeys.forEach(function (key, i) {\n    var k = [];\n    for (var j = 0; j < i + 1; j++) {\n      for (var l = 1; l < 6; l++) {\n        k.push(flatNotes[j] + 12 * l);\n      }\n    }\n    tuneKey[key] = k;\n  });\n}\n\n\n//# sourceURL=webpack://PN/./src/wave/encoder.js?");

/***/ }),

/***/ "./src/wave/filter.js":
/*!****************************!*\
  !*** ./src/wave/filter.js ***!
  \****************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LowPassFilter: () => (/* binding */ LowPassFilter),\n/* harmony export */   LpAcousticGuitar: () => (/* binding */ LpAcousticGuitar),\n/* harmony export */   LpBanjo: () => (/* binding */ LpBanjo),\n/* harmony export */   LpBanjo2: () => (/* binding */ LpBanjo2),\n/* harmony export */   LpCello: () => (/* binding */ LpCello),\n/* harmony export */   LpDefault: () => (/* binding */ LpDefault),\n/* harmony export */   LpEvolvingLead: () => (/* binding */ LpEvolvingLead),\n/* harmony export */   LpFunckLead: () => (/* binding */ LpFunckLead),\n/* harmony export */   LpOrgan60: () => (/* binding */ LpOrgan60),\n/* harmony export */   LpPassEvolvingLead: () => (/* binding */ LpPassEvolvingLead),\n/* harmony export */   LpPercussiveStaccatoPad: () => (/* binding */ LpPercussiveStaccatoPad),\n/* harmony export */   LpThickBass: () => (/* binding */ LpThickBass),\n/* harmony export */   LpTrumpet: () => (/* binding */ LpTrumpet),\n/* harmony export */   filters: () => (/* binding */ filters)\n/* harmony export */ });\n//filter\nvar filters = {};\nfilters[\"LpPassEvolvingLead\"] = LpPassEvolvingLead;\nfilters[\"LpEvolvingLead\"] = LpEvolvingLead;\nfilters[\"LpThickBass\"] = LpThickBass;\nfilters[\"LpFunckLead\"] = LpFunckLead;\nfilters[\"LpPercussiveStaccatoPad\"] = LpPercussiveStaccatoPad;\nfilters[\"LpOrgan60\"] = LpOrgan60;\nfilters[\"LpTrumpet\"] = LpTrumpet;\nfilters[\"LpDefault\"] = LpDefault;\nfilters[\"LpCello\"] = LpCello;\nfilters[\"LpAcousticGuitar\"] = LpAcousticGuitar;\nfunction LpDefault(sample, amplitude, sampleRate, prevState) {\n  return sample;\n}\nfunction LpPassEvolvingLead(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 236;\n  var resonance = 0.85;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpEvolvingLead(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 472;\n  var resonance = 0.92;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpThickBass(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 170; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0.65;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpFunckLead(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 7200; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0.9;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpPercussiveStaccatoPad(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 220; // Low-pass filter cutoff frequency in Hz\n  var resonance = 1;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpOrgan60(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 2800; // Low-pass filter cutoff frequency in Hz\n  var resonance = 1;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpTrumpet(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 156; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0.64;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpBanjo(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 2900; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0.00001;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpBanjo2(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 1500; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpCello(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 40; // Low-pass filter cutoff frequency in Hz\n  var resonance = 1;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LpAcousticGuitar(sample, amplitude, sampleRate, prevState) {\n  var cutoffFreq = 380; // Low-pass filter cutoff frequency in Hz\n  var resonance = 0.3;\n  return LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState);\n}\nfunction LowPassFilter(sample, cutoffFreq, amplitude, sampleRate, resonance, prevState) {\n  cutoffFreq = cutoffFreq * amplitude;\n  var RC = 1 / (2 * Math.PI * cutoffFreq);\n  var alpha = RC / (RC + 1 / sampleRate);\n  var filteredSample = alpha * (prevState.value + sample - resonance * prevState.resonanceGain);\n  prevState.resonanceGain = resonance * (filteredSample - prevState.value);\n  prevState.value = filteredSample;\n  return filteredSample;\n}\n\n\n//# sourceURL=webpack://PN/./src/wave/filter.js?");

/***/ }),

/***/ "./src/wave/harmonic.js":
/*!******************************!*\
  !*** ./src/wave/harmonic.js ***!
  \******************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   base: () => (/* binding */ base),\n/* harmony export */   first: () => (/* binding */ first),\n/* harmony export */   harmonics: () => (/* binding */ harmonics),\n/* harmony export */   pulseWave: () => (/* binding */ pulseWave),\n/* harmony export */   sawtooth: () => (/* binding */ sawtooth),\n/* harmony export */   second: () => (/* binding */ second),\n/* harmony export */   sine: () => (/* binding */ sine),\n/* harmony export */   square: () => (/* binding */ square),\n/* harmony export */   stringed: () => (/* binding */ stringed),\n/* harmony export */   third: () => (/* binding */ third),\n/* harmony export */   triangle: () => (/* binding */ triangle)\n/* harmony export */ });\n// harmonic.js\n\n// The harmonic describes the additional harmonics added to the fundamental frequency\nvar harmonics = {};\n\n// Initialize harmonics\nharmonics[\"first\"] = first;\nharmonics[\"second\"] = second;\nharmonics[\"third\"] = third;\nharmonics[\"stringed\"] = stringed;\nharmonics[\"triangle\"] = triangle;\nharmonics[\"sine\"] = sine;\nharmonics[\"square\"] = square;\nharmonics[\"sawtooth\"] = sawtooth;\nharmonics[\"pulseWave\"] = pulseWave;\n\n// Waveform functions\nfunction triangle(input) {\n  return 2 * Math.abs(2 * (input % 1) - 1) - 1;\n}\nfunction sine(input) {\n  return Math.sin(2 * Math.PI * input);\n}\nfunction square(input) {\n  return 2 * (input % 1) - 1;\n}\nfunction sawtooth(input) {\n  return 2 * (input % 1) - 1;\n}\nfunction pulseWave(frequency, time, pulseWidth) {\n  var period = 1 / frequency;\n  var phase = time % period;\n  return phase < pulseWidth * period ? 1 : -1;\n}\n\n// Base function to calculate the base frequency\nfunction base(input) {\n  return 2 * Math.PI * input;\n}\n\n// First harmonic: fundamental frequency\nfunction first(input) {\n  return Math.sin(base(input));\n}\n\n// Second harmonic: adds the second harmonic (double the base frequency)\nfunction second(input) {\n  return Math.sin(base(input)) + Math.sin(base(input) * 2);\n}\n\n// Third harmonic: adds the third harmonic (triple the base frequency)\nfunction third(input) {\n  return Math.sin(base(input)) + Math.sin(base(input) * 2) + Math.sin(base(input) * 3);\n}\nfunction triangleHarmonics(time, frequency, harmonics) {\n  var result = 0;\n  for (var n = 1; n <= harmonics; n++) {\n    // Odd harmonics only: 1, 3, 5, etc.\n    if (n % 2 === 1) {\n      var harmonicFrequency = frequency * n; // Harmonic frequency\n      var harmonicAmplitude = 1 / (n * n); // Amplitude falls off as 1/n^2 for triangle wave\n      result += harmonicAmplitude * Math.sin(2 * Math.PI * harmonicFrequency * time);\n    }\n  }\n  return result * 8 / Math.pow(Math.PI, 2); // Normalize for triangle wave\n}\n\n// Stringed instrument harmonic: complex combination of harmonics\nfunction stringed(input) {\n  return Math.sin(input) + Math.sign(Math.sin(input * 2)) * 0.5;\n}\n\n// Export the harmonics object\n\n\n//# sourceURL=webpack://PN/./src/wave/harmonic.js?");

/***/ }),

/***/ "./src/wave/lowFrequency.js":
/*!**********************************!*\
  !*** ./src/wave/lowFrequency.js ***!
  \**********************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LfBanjo: () => (/* binding */ LfBanjo),\n/* harmony export */   LfCello: () => (/* binding */ LfCello),\n/* harmony export */   LfDefault: () => (/* binding */ LfDefault),\n/* harmony export */   LfEvolvingLead: () => (/* binding */ LfEvolvingLead),\n/* harmony export */   LfEvolvingLeadPad: () => (/* binding */ LfEvolvingLeadPad),\n/* harmony export */   LfFunckLead: () => (/* binding */ LfFunckLead),\n/* harmony export */   LfOrgan60: () => (/* binding */ LfOrgan60),\n/* harmony export */   LfPercussiveStaccatoPad: () => (/* binding */ LfPercussiveStaccatoPad),\n/* harmony export */   LfThickBass: () => (/* binding */ LfThickBass),\n/* harmony export */   LfTrumpet: () => (/* binding */ LfTrumpet),\n/* harmony export */   lowFrequency: () => (/* binding */ lowFrequency)\n/* harmony export */ });\nvar lowFrequency = {};\nlowFrequency[\"LfEvolvingLead\"] = LfEvolvingLead;\nlowFrequency[\"LfEvolvingLeadPad\"] = LfEvolvingLeadPad;\nlowFrequency[\"LfFunckLead\"] = LfFunckLead;\nlowFrequency[\"LfThickBass\"] = LfThickBass;\nlowFrequency[\"LfPercussiveStaccatoPad\"] = LfPercussiveStaccatoPad;\nlowFrequency[\"LfOrgan60\"] = LfOrgan60;\nlowFrequency[\"LfTrumpet\"] = LfTrumpet;\nlowFrequency[\"LfBanjo\"] = LfBanjo;\nlowFrequency[\"LfCello\"] = LfCello;\nlowFrequency[\"LfDefault\"] = LfDefault;\nfunction LfEvolvingLead(time) {\n  var frequency = 10;\n  var depth = 0.2;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfEvolvingLeadPad(time) {\n  var frequency = 35;\n  var depth = 0.5;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfFunckLead(time) {\n  var frequency = 18;\n  var depth = 0.2;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfThickBass(time) {\n  var frequency = 15; // LFO frequency in Hz\n  var depth = 0.2;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfPercussiveStaccatoPad(time) {\n  var frequency = 0.6; // LFO frequency in Hz\n  var depth = 0.2;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfOrgan60(time) {\n  var frequency = 1; // LFO frequency in Hz\n  var depth = 0.08;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfTrumpet(time) {\n  var frequency = 15; // LFO frequency in Hz\n  var depth = 0.15;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfBanjo(time) {\n  var frequency = 10; // LFO frequency in Hz\n  var depth = 0.1;\n  return 2 / Math.PI * Math.asin(Math.sin(2 * Math.PI * frequency * time)) * depth;\n}\nfunction LfCello(time) {\n  var frequency = 7.5; // LFO frequency in Hz\n  var depth = 0.05;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\nfunction LfDefault(time) {\n  var frequency = 7.5; // LFO frequency in Hz\n  var depth = 0.05;\n  return Math.sin(2 * Math.PI * frequency * time) * depth;\n}\n\n\n//# sourceURL=webpack://PN/./src/wave/lowFrequency.js?");

/***/ }),

/***/ "./src/wave/player.js":
/*!****************************!*\
  !*** ./src/wave/player.js ***!
  \****************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createNote: () => (/* binding */ createNote),\n/* harmony export */   createSong: () => (/* binding */ createSong),\n/* harmony export */   singVoice: () => (/* binding */ singVoice)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n/* harmony import */ var _encoder_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./encoder.js */ \"./src/wave/encoder.js\");\n/* harmony import */ var _harmonic_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./harmonic.js */ \"./src/wave/harmonic.js\");\n/* harmony import */ var _instruments_instruments_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../instruments/instruments.js */ \"./src/instruments/instruments.js\");\n/* harmony import */ var _input_parseStringInput_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../input/parseStringInput.js */ \"./src/input/parseStringInput.js\");\n/* harmony import */ var _pitchFrequencies_json__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../pitchFrequencies.json */ \"./src/pitchFrequencies.json\");\n/* harmony import */ var _input_wavProcessor_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../input/wavProcessor.js */ \"./src/input/wavProcessor.js\");\n/* harmony import */ var _synth_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./synth.js */ \"./src/wave/synth.js\");\nfunction _construct(t, e, r) { if (_isNativeReflectConstruct()) return Reflect.construct.apply(null, arguments); var o = [null]; o.push.apply(o, e); var p = new (t.bind.apply(t, o))(); return r && _setPrototypeOf(p, r.prototype), p; }\nfunction _setPrototypeOf(t, e) { return _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function (t, e) { return t.__proto__ = e, t; }, _setPrototypeOf(t, e); }\nfunction _isNativeReflectConstruct() { try { var t = !Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); } catch (t) {} return (_isNativeReflectConstruct = function _isNativeReflectConstruct() { return !!t; })(); }\nfunction _toConsumableArray(r) { return _arrayWithoutHoles(r) || _iterableToArray(r) || _unsupportedIterableToArray(r) || _nonIterableSpread(); }\nfunction _nonIterableSpread() { throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _iterableToArray(r) { if (\"undefined\" != typeof Symbol && null != r[Symbol.iterator] || null != r[\"@@iterator\"]) return Array.from(r); }\nfunction _arrayWithoutHoles(r) { if (Array.isArray(r)) return _arrayLikeToArray(r); }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\n\n\n\n\n\n\n\n\n\n/**\n * Creates a musical note with the given note name.\n * If no instrument is selected, it defaults to Piano.\n *\n * @param {string|number} noteName - The name or number of the musical note (e.g., \"A4\", \"440\").\n * @returns {Note|undefined} - A new Note instance with the specified pitch, or undefined if the note is not found.\n *\n * @example\n * // Select an instrument and create a note\n * PN.instrument('cello');    // Select piano instrument\n * const note = createNote('C4'); // Creates a note with frequency for C4\n * console.log(note);         // Logs the created note\n * PN.save();\n */\n\nfunction createNote(noteName) {\n  // Set default instrument to piano if no instrument is selected\n  if (!_pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument) {\n    console.log(\"No instrument selected, defaulting to Banjo.\");\n    _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument = new _instruments_instruments_js__WEBPACK_IMPORTED_MODULE_3__.Instruments().Banjo(); // Default to piano\n  }\n  var frequency = _pitchFrequencies_json__WEBPACK_IMPORTED_MODULE_5__[noteName];\n  if (!frequency) {\n    frequency = parseInt(noteName);\n    if (isNaN(frequency)) {\n      console.log(\"Note \".concat(noteName, \" not found!\"));\n      return;\n    }\n  }\n  if (typeof noteName === \"number\") {\n    frequency = noteName;\n  }\n  if (!frequency) {\n    console.log(\"Please enter a number or musical note\");\n    return;\n  }\n  var note = new _encoder_js__WEBPACK_IMPORTED_MODULE_1__.Note([frequency],\n  // Frequency for the note\n  [0],\n  // No accidentals\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].duration,\n  // Use PN's duration\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument,\n  // Use the selected instrument's envelope\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].volume,\n  // Use PN's volume level\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio);\n  console.log(\"Created note \".concat(noteName, \" with frequency \").concat(frequency));\n  return note;\n}\n\n/**\n * Creates a song based on the input data.\n * The song is constructed from a series of note strings and durations.\n * Notes are processed and encoded into a Tune instance.\n *\n * @param {Array} songData - An array of song sections and note data, in string format.\n * @returns {Array} - The encoded song data.\n *\n * @example\n * // Define song data\n * const songData = [\n *  \"ch1[1.5:A4-F5]\",\n *  \"ch2[0.5:C4]\",\n *  \"ch1[2.0:G3-E4-D4]\"\n * ];\n *\n * // Create a song\n * PN.setVolume(0.5); // Set volume level\n * const song = createSong(songData); // Create a song from the input data\n * console.log(song); // Logs the encoded song data\n */\n\n// Helper to create a song\nfunction createSong(songData) {\n  var myTune = new _encoder_js__WEBPACK_IMPORTED_MODULE_1__.Tune(_pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].key, [],\n  // ch1: Will be filled with notes\n  []) // ch2: Will be filled with notes\n  ;\n  var parsedData = (0,_input_parseStringInput_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(songData);\n  for (var channel in parsedData) {\n    var channelData = parsedData[channel];\n    if (channel === \"ch1\") {\n      channelData.forEach(function (entry) {\n        var duration = entry.duration,\n          notes = entry.notes;\n        _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].duration = duration;\n        notes.forEach(function (noteName) {\n          var note = createNote(noteName);\n          if (note) {\n            myTune.ch1.push(note);\n          }\n        });\n      });\n    } else if (channel === \"ch2\") {\n      channelData.forEach(function (entry) {\n        var duration = entry.duration,\n          notes = entry.notes;\n        _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].duration = duration;\n        notes.forEach(function (noteName) {\n          var note = createNote(noteName);\n          if (note) {\n            myTune.ch2.push(note);\n          }\n        });\n      });\n    }\n  }\n\n  // Concatenate all notes to form the song\n  var songDataOutput = myTune.encodePlane();\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].songDataOutput = songDataOutput;\n  return songDataOutput;\n}\n\n/**\n * Creates a musical note with the given note name.\n * If no instrument is selected, it defaults to Piano.\n *\n * @param {string} noteName - The name of audio file you wish to replicate.\n * @returns {File|undefined} - A new audio file instance with the specified pitch, or undefined if the note is not found.\n *\n * @example\n * // Select an instrument and create a note\n *      // Wrap everything in an async function\n *      async function runPNExample() {\n *          console.log(PN);  // This should print the PN object\n *           PN.instrument('Piano'); // Select the instrument\n *           // PN.setVolume(0.5); // Set volume (optional)\n *\n *           // Wait for PN.singVoice to complete\n *           const song = await PN.singVoice('recording2.wav');\n *\n *           console.log(\"Song created:\", song);\n *           console.log(PN.volume);  // Logs the current volume\n *               setTimeout(() => {\n *                   PN.save(); // Call save after the delay\n *                   saveLogToFile(logMessages);\n *\n *               }, 8000); // Delay in milliseconds (5000ms = 5s)\n *       }\n *\n *       // Run the function\n *       runPNExample();\n */\n\nfunction singVoice(audioFile) {\n  var numChannels = 100;\n  (0,_input_wavProcessor_js__WEBPACK_IMPORTED_MODULE_6__.readWavFile)(audioFile, function (voiceFrequencies) {\n    var skeleton = voiceFrequencies;\n    var myTune = _construct(_encoder_js__WEBPACK_IMPORTED_MODULE_1__.Tune, [_pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].key].concat(_toConsumableArray(Array(numChannels).fill([]))));\n    var channels = Array.from({\n      length: numChannels\n    }, function (_, i) {\n      return myTune[\"ch\".concat(i + 1)];\n    });\n    for (var i = 0; i < skeleton.length; i++) {\n      console.log(\"Voice number \".concat(i + 1));\n      skeleton[i].forEach(function (data, index) {\n        var note = new _encoder_js__WEBPACK_IMPORTED_MODULE_1__.Note([Math.round(data[0])],\n        // Frequency\n        [0],\n        // No accidentals\n        data[2],\n        // Duration\n        _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].currentInstrument,\n        // Oscillators\n        _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic1, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].step, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filter2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width1, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].width2, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].filterEnv, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lfoWave, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].glideTime, data[1],\n        // Volume\n        _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].multiplier, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseLevel, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].noiseState, _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ratio);\n        if (note) {\n          channels[i].push(note);\n        }\n      });\n    }\n    var songDataOutput = myTune.encode();\n    _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].songDataOutput = songDataOutput;\n    return songDataOutput;\n  });\n}\n\n\n//# sourceURL=webpack://PN/./src/wave/player.js?");

/***/ }),

/***/ "./src/wave/setProperties.js":
/*!***********************************!*\
  !*** ./src/wave/setProperties.js ***!
  \***********************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   setDuration: () => (/* binding */ setDuration),\n/* harmony export */   setHarmonic: () => (/* binding */ setHarmonic),\n/* harmony export */   setVolume: () => (/* binding */ setVolume)\n/* harmony export */ });\n/* harmony import */ var _pn_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../pn.js */ \"./src/pn.js\");\n\n\n/**\n * Sets the duration for notes in the PN object.\n *\n * @param {number} duration - The duration of the note in seconds.\n *\n * @example\n * // Set the duration of notes to 1 second\n * setDuration(1);\n * console.log(PN.duration);  // Logs: 1\n */\nfunction setDuration(duration) {\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].duration = duration;\n  console.log(\"Duration set to \".concat(duration, \" seconds\"));\n}\n\n/**\n * Sets the volume level for notes in the PN object.\n *\n * @param {number} volume - The volume level (e.g., between 0 and 1).\n *\n * @example\n * // Set the volume of notes to 0.75 (75% of max volume)\n * setVolume(0.75);\n * console.log(PN.volume);  // Logs: 0.75\n */\nfunction setVolume(volume) {\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].volume = volume;\n  console.log(\"Volume level set to \".concat(volume));\n}\n\n/**\n * Sets the harmonic function for notes in the PN object.\n *\n * @param {function} harmonicFunc - The harmonic function to apply to the notes.\n *\n * @example\n * // Set the harmonic function to 'first'\n * PN.setHarmonic(first);\n * console.log(PN.harmonic);  // Logs: [function: first]\n */\nfunction setHarmonic(harmonicFunc) {\n  _pn_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].harmonic = harmonicFunc;\n  console.log(\"Harmonic function set \".concat(harmonicFunc));\n}\n\n\n//# sourceURL=webpack://PN/./src/wave/setProperties.js?");

/***/ }),

/***/ "./src/wave/synth.js":
/*!***************************!*\
  !*** ./src/wave/synth.js ***!
  \***************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   calculateFrequency: () => (/* binding */ calculateFrequency),\n/* harmony export */   concat: () => (/* binding */ concat),\n/* harmony export */   getInputInstrument: () => (/* binding */ getInputInstrument),\n/* harmony export */   inKey: () => (/* binding */ inKey),\n/* harmony export */   inNote: () => (/* binding */ inNote),\n/* harmony export */   noteData: () => (/* binding */ noteData),\n/* harmony export */   noteData2: () => (/* binding */ noteData2),\n/* harmony export */   rest: () => (/* binding */ rest),\n/* harmony export */   setInputInstrument: () => (/* binding */ setInputInstrument),\n/* harmony export */   whiteNoise: () => (/* binding */ whiteNoise)\n/* harmony export */ });\n/* harmony import */ var _harmonic_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./harmonic.js */ \"./src/wave/harmonic.js\");\nfunction _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\nfunction _iterableToArrayLimit(r, l) { var t = null == r ? null : \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t[\"return\"] && (u = t[\"return\"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }\nfunction _arrayWithHoles(r) { if (Array.isArray(r)) return r; }\n// synth.js\n\n\nvar instrument;\n\n// Sample rate is assumed to be constant\nvar sampleRate = 44100,\n  bitDepth = 16,\n  numChannels = 2,\n  wavAudioFormat = 1,\n  tolerance = 1500;\n\n// Generate rest (silence) data for the specified duration\nfunction rest(duration) {\n  var restData = [];\n  var totalSamples = Math.floor(duration * sampleRate);\n  for (var i = 0; i < totalSamples; i++) {\n    restData.push(0); // Silence\n  }\n  return restData;\n}\n\n// Concatenates an array of note arrays\nfunction concat() {\n  for (var _len = arguments.length, notes = new Array(_len), _key = 0; _key < _len; _key++) {\n    notes[_key] = arguments[_key];\n  }\n  return notes.flat(); // Flatten all note arrays into one\n}\n\n// Calculate frequency from pitch step\nfunction semitone(frequency, step) {\n  return frequency * Math.pow(2, step / 12.0); // A440 standard\n}\nfunction applyGlide(targetFreq, currentFreq, glideTime, timeStep) {\n  var glideStep = (targetFreq - currentFreq) * (timeStep / glideTime);\n  return currentFreq + glideStep;\n}\nfunction whiteNoise(bool) {\n  if (bool === true) {\n    return Math.random() * 2 - 1;\n  }\n  return 1;\n}\nfunction mixing(osc1, osc2, a, b, c) {\n  return (osc1 * a + osc2 * b) / c;\n}\n\n// Returns the note data based on frequency, duration, envelope, harmonic, and volume\nfunction noteData(frequency, duration, envelope, harmonic1, harmonic2, step, filter, filter2, width1, width2, filterEnv, lfoWave, glideTime, volume, multiplier, noiseLevel, noiseState, ratio) {\n  var length = duration * sampleRate * multiplier;\n  var filterState = {\n    value: 0,\n    resonanceGain: 0\n  }; // Initial filter state\n\n  var data = Array.apply(null, Array(length)).map(function () {\n    return 0;\n  });\n  for (var i = 0; i < length; i++) {\n    var time = i / sampleRate;\n    //const x = volume * envelope(t , duration )* harmonic(frequency * t);\n    var frequency2 = semitone(frequency, step);\n    frequency = applyGlide(frequency, frequency, glideTime, 1 / sampleRate);\n    frequency2 = applyGlide(frequency2, frequency2, glideTime, 1 / sampleRate);\n    var oscillator1 = 0,\n      oscillator2 = 0;\n    if (harmonic1 == _harmonic_js__WEBPACK_IMPORTED_MODULE_0__.pulseWave) {\n      oscillator1 = harmonic1(frequency, time, width1);\n    } else {\n      oscillator1 = harmonic1(frequency * time);\n    }\n    var oscillator2 = 0;\n    if (harmonic2 == _harmonic_js__WEBPACK_IMPORTED_MODULE_0__.pulseWave) {\n      oscillator1 = harmonic2(frequency, time, width2);\n    } else {\n      oscillator2 = harmonic2(frequency2 * time);\n    }\n\n    // Mix the oscillators\n    var sample = mixing(oscillator1, oscillator2, ratio[0], ratio[1], ratio[2]) + noiseLevel * whiteNoise(noiseState);\n    // Apply LFO for vibrato\n    sample *= 1 + lfoWave(time);\n    var amplitude = filterEnv(time);\n    // Apply amlitude envelope to the cutoff frequency\n\n    sample = filter(sample, amplitude, sampleRate, filterState);\n    sample = filter2(sample, amplitude, sampleRate, filterState);\n    var amp = envelope(time, duration);\n    //console.log(sample,volume);\n    sample *= amp;\n    data[i] = sample * volume;\n  }\n  return data;\n}\nfunction frequencyScale(step) {\n  return 440.0 * Math.pow(2, step / 12.0);\n}\nfunction floorTowardsZero(num) {\n  console.log(Math.floor(num));\n  return Math.floor(num);\n}\nfunction noteData2(frequency, duration, envelope, harmonic, volume) {\n  var data = [];\n  for (var i = 0; i < duration; i += 1.0 / sampleRate) {\n    var x = Math.floor(volume * envelope(i, duration) * harmonic(frequency * i));\n    data.push(x);\n  }\n  return data;\n}\n\n// Check if the given note is in the key signature\nfunction inKey(keys, note) {\n  return keys.includes(note);\n}\n\n// Check if the note is part of the specified key\nfunction inNote(notes, note) {\n  return notes.includes(note);\n}\n\n// utils.js\n\n/**\n * Get the frequency of a note based on its distance from A4 (440 Hz).\n * @param {string} note - The note (e.g., 'C4', 'A4', 'G#5').\n * @returns {number} - The frequency of the note in Hz.\n */\nfunction calculateFrequency(note) {\n  var noteMap = {\n    C: -9,\n    \"C#\": -8,\n    D: -7,\n    \"D#\": -6,\n    E: -5,\n    F: -4,\n    \"F#\": -3,\n    G: -2,\n    \"G#\": -1,\n    A: 0,\n    \"A#\": 1,\n    B: 2\n  };\n  var noteUpper = note.toUpperCase();\n  var parsedNote = noteUpper.match(/^([A-G]#?)(\\d)$/);\n  if (!parsedNote) throw new Error(\"Invalid note format: \".concat(note));\n  var _parsedNote = _slicedToArray(parsedNote, 3),\n    noteName = _parsedNote[1],\n    octave = _parsedNote[2];\n  var semitoneDistance = noteMap[noteName] + (parseInt(octave) - 4) * 12;\n  return 440 * Math.pow(2, semitoneDistance / 12); // Frequency calculation\n}\n\n// Generate wave value based on oscillator type\nfunction generateWaveValue(type, frequency, time) {\n  var phase = 2 * Math.PI * frequency * time;\n  switch (type) {\n    case \"sine\":\n      return Math.sin(phase);\n    case \"triangle\":\n      return 2 * Math.abs(2 * (time * frequency - Math.floor(time * frequency + 0.5))) - 1;\n    case \"square\":\n      return Math.sign(Math.sin(phase));\n    case \"sawtooth\":\n      return 2 * (time * frequency - Math.floor(time * frequency + 0.5));\n    case \"n0\":\n      // White noise\n      return Math.random() * 2 - 1;\n    default:\n      return 0;\n    // Default to no contribution if unknown wave type\n  }\n}\n\n// Calculate AHDSR envelope value\nfunction calculateDynamicADSR(time, duration, a, d, s, r, h) {\n  var attackEnd = a;\n  var holdEnd = a + h;\n  var decayEnd = holdEnd + d;\n  var releaseStart = duration - r;\n  if (time < attackEnd) {\n    return time / a; // Attack phase (linear ramp)\n  } else if (time < holdEnd) {\n    return 1; // Hold phase (constant at peak)\n  } else if (time < decayEnd) {\n    return 1 - (time - holdEnd) / d * (1 - s); // Decay phase\n  } else if (time < releaseStart) {\n    return s; // Sustain phase\n  } else if (time <= duration) {\n    return s * (1 - (time - releaseStart) / r); // Release phase\n  } else {\n    return 0; // Beyond duration\n  }\n}\nfunction setInputInstrument(newInstrument) {\n  instrument = newInstrument;\n}\nfunction getInputInstrument() {\n  if (instrument === \"voice\") {\n    return \"voice\";\n  } else {\n    return \"note\";\n  }\n}\n\n//# sourceURL=webpack://PN/./src/wave/synth.js?");

/***/ }),

/***/ "./src/pitchFrequencies.json":
/*!***********************************!*\
  !*** ./src/pitchFrequencies.json ***!
  \***********************************/
/***/ ((module) => {

eval("module.exports = /*#__PURE__*/JSON.parse('{\"C1\":32.7,\"C1#\":34.65,\"D1\":36.71,\"D1b\":38.89,\"E1\":41.2,\"F1\":43.65,\"F1#\":46.25,\"G1\":49,\"G1b\":51.91,\"A1\":55,\"A1#\":58.27,\"B1\":61.74,\"C2\":65.41,\"C2#\":69.3,\"D2\":73.42,\"D2b\":77.78,\"E2\":82.41,\"F2\":87.31,\"F2#\":92.5,\"G2\":98,\"G2b\":103.83,\"A2\":110,\"A2#\":116.54,\"B2\":123.47,\"C3\":130.81,\"C3#\":138.59,\"D3\":146.83,\"D3b\":155.56,\"E3\":164.81,\"F3\":174.61,\"F3#\":185,\"G3\":196,\"G3b\":207.65,\"A3\":220,\"A3#\":233.08,\"B3\":246.94,\"C4\":261.63,\"C4#\":277.18,\"D4\":293.66,\"D4b\":311.13,\"E4\":329.63,\"F4\":349.23,\"F4#\":369.99,\"G4\":392,\"G4b\":415.3,\"A4\":440,\"A4#\":466.16,\"B4\":493.88,\"C5\":523.25,\"C5#\":554.37,\"D5\":587.33,\"D5b\":622.25,\"E5\":659.25,\"F5\":698.46,\"F5#\":739.99,\"G5\":783.99,\"G5b\":830.61,\"A5\":880,\"A5#\":932.33,\"B5\":987.77,\"C6\":1046.5,\"C6#\":1108.73,\"D6\":1174.66,\"D6b\":1244.51,\"E6\":1318.51,\"F6\":1396.91,\"F6#\":1479.98,\"G6\":1567.98,\"G6b\":1661.22,\"A6\":1760,\"A6#\":1864.66,\"B6\":1975.53,\"C7\":2093,\"C7#\":2217.46,\"D7\":2349.32,\"D7b\":2489.02,\"E7\":2637.02,\"F7\":2793.83,\"F7#\":2959.96,\"G7\":3135.96,\"G7b\":3322.44,\"A7\":3520,\"A7#\":3729.31,\"B7\":3951.07,\"C8\":4186.01}');\n\n//# sourceURL=webpack://PN/./src/pitchFrequencies.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});